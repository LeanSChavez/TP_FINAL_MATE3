{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9757af98",
   "metadata": {},
   "source": [
    "## Introducción.\n",
    "\n",
    "El dataset trabajado cuenta con un registro de 50 millones de manos jugadas de \"BlackJack\" usando un simulador. Cada registro cuenta con 12 columnas, de las cuales se valerá nuestra red neuronal para predecir la acción a tomar:\n",
    "- Pedir una carta (HIT).\n",
    "- No pedir otra carta (STAND).\n",
    "\n",
    "## Parte 1 - Análisis de la base de datos.\n",
    "\n",
    "### 1. Descripción de columnas.\n",
    "\n",
    "Nuestro dataset cuenta con muchas columnas que terminaremos reduciendo a las que consideramos mas relevantes. Sin embargo, resumiremos la utilidad de la totalidad de ellas:\n",
    "- \"Shoe id\": Es un identificador del mazo utilizado (del 1 al 8).\n",
    "- \"Cards remaining\": Son las cartas restantes del mazo al empezar la ronda.\n",
    "- \"Dealer up\": Es la carta visible del \"dealer\" al empezar la ronda.\n",
    "- \"Initial hand\": Son las 2 cartas dadas al jugador.\n",
    "- \"Dealer final\": Cartas con las que termina el dealer al final de la ronda.\n",
    "- \"Dealer final value\":  Es el valor de las cartas mencionadas en la columna anterior.\n",
    "- \"Player final\": Al igual que dealer final, son las cartas con las que termina el jugador.\n",
    "- \"Player final value\": La suma del valor de las cartas del jugador.\n",
    "- \"Actions taken\": Es la acción que toma el el jugador, \"H\" o \"S\".\n",
    "- \"Run count\": Identificador de la ronda a jugar.\n",
    "\n",
    "### 2. Analisis de correlaciones.\n",
    "\n",
    "Por un lado, consideramos varias columnas como poco impactantes, como por ejemplo:\n",
    "- Shoe id: El identificador del mazo no afecta a la estrategia del juego.\n",
    "- Run count: No afecta el numero de ronda jugada con la decisión a tomar.\n",
    "- Cards remaining: A menos que se esté haciendo un conteo de cartas (lo cual es un analisis muy avanzado), no suele impactar en la decisión final.\n",
    "\n",
    "Ahora bien, hay columnas que representan correlacionves clave para la decisión a tomar:\n",
    "- Initial hand => Actions taken: La correlación en este caso es alta(positiva o negativamente). Las manos de 17 a 21 correlacionan con STAND, mientras que las menores a 11 se correlacionan con HIT\n",
    "- Dealer up => Actions taken: La correlación es alta y negativa, ya que si el dealer tiene una mano \"alta\", el jugador tenderá a hacer HIT, y si la mano del dealer es \"baja\", el jugador hará STAND.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce80f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dealer_up</th>\n",
       "      <th>initial_hand</th>\n",
       "      <th>actions_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[6, 3]</td>\n",
       "      <td>[['H', 'H']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[10, 5]</td>\n",
       "      <td>[['R']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[6, 8]</td>\n",
       "      <td>[['S']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>[7, 3]</td>\n",
       "      <td>[['D']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[10, 5]</td>\n",
       "      <td>[['S']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dealer_up initial_hand actions_taken\n",
       "0         10       [6, 3]  [['H', 'H']]\n",
       "1         10      [10, 5]       [['R']]\n",
       "2          2       [6, 8]       [['S']]\n",
       "3          8       [7, 3]       [['D']]\n",
       "4          6      [10, 5]       [['S']]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Me interesa: ; dealer_up; initial_hand; actions_taken\n",
    "columnas = ['dealer_up','initial_hand','actions_taken']\n",
    "df = pd.read_csv(\"csv_reducido\",usecols=columnas)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caae01a",
   "metadata": {},
   "source": [
    "### 3 - Análisis de factibilidad.\n",
    "\n",
    "Consideramos el dataset elegido como idóneo para entrar una red neuronal, y sobretodo con las columnas seleccionadas.\n",
    "Dichas columnas son predictoras naturales de la acción que se tomará. A su vez, esta columna de decisión es una variable objetivo binaria y categórica, ideal para la tarea de clasificación.\n",
    "\n",
    "Dicho esto, lo que en última medida predecirá la red, es la acción ideal a tomar, una vez presentada la carta del dealer así como las del jugador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6207d",
   "metadata": {},
   "source": [
    "### 4 - Datos atípicos y limpieza.\n",
    "\n",
    "Al regirnos a las reglas mismas del Blackjack, es imposible encontrar Outliers por definición.\n",
    "\n",
    "\n",
    "### 5 - Transformaciones preliminares.\n",
    "\n",
    "Los datos presentados originalmente no servirán de mucho, puesto que tenemos listas que la red neuronal no entenderá, así como strings, por lo que debemos convertir initial_hand y actions_taken en variables que la red sí pueda comprender.\n",
    "En este caso sumaremos los valores de las cartas de initial_hand para llegar a el valor total del jugador. Con respecto a actions_taken, nos quedaremos solamente con HIT y STAND, que son las 2 acciones mas comunes, y les daremos un valor binario, ideal para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b1484394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dealer_up  hand_value  action\n",
      "0         10           9       1\n",
      "2          2          14       0\n",
      "4          6          15       0\n",
      "5         11           9       1\n",
      "8          6          12       0\n"
     ]
    }
   ],
   "source": [
    "# Sumar toda la initial hand para que sea un valor\n",
    "df['hand_value'] = df['initial_hand'].apply(lambda x: sum(eval(x)) if isinstance(x, str) else sum(x))\n",
    "\n",
    "# Solo me interesa la primera accion, si Hitteo, o si hizo Stay\n",
    "acciones_validas = ['H','S']\n",
    "\n",
    "\n",
    "def get_accion_valida(actions):\n",
    "    try:\n",
    "        actions = eval(actions)[0] if isinstance(actions, str) else actions[0]\n",
    "    except Exception:\n",
    "        return None\n",
    "    for action in actions:\n",
    "        if action in acciones_validas:\n",
    "            return action\n",
    "    return None\n",
    "\n",
    "# Recorro la columna actions taken y aplico la funcion para filtrar y le asigno un valor binario\n",
    "df['first_action'] = df['actions_taken'].apply(get_accion_valida)\n",
    "df = df[df['first_action'].notnull()]\n",
    "df['action'] = df['first_action'].map({'S':0,'H':1})\n",
    "\n",
    "# Creo ya las columnas con todos valores listos para interpretarse\n",
    "inputs = df[['dealer_up','hand_value']]\n",
    "outputs = df[['action']]\n",
    "df_preview = pd.concat([inputs, outputs], axis=1)\n",
    "print(df_preview.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9856c",
   "metadata": {},
   "source": [
    "El siguiente paso será normalizar los datos que tenemos. \n",
    "Aplicaremos el **MinMaxScaler** de **sklearn**, que lo que hará será convertir nuestro hand value a valores de entre 0 y 1, pero teniendo en cuenta que los valores originales iban de entre 4 a 21.\n",
    "Tambien escalaremos el dealer_up de la misma forma, pero teniendo en cuenta en este caso que los valores originales iban de 2 a 11. Es decir, la escala que se utiliza para convertir los valores entre 0 y 1 será diferente en ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "53e4cab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dealer_up_normalizado</th>\n",
       "      <th>hand_value_normalizado</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dealer_up_normalizado  hand_value_normalizado  action\n",
       "0               0.888889                0.294118       1\n",
       "1               0.000000                0.588235       0\n",
       "2               0.444444                0.647059       0\n",
       "3               1.000000                0.294118       1\n",
       "4               0.444444                0.470588       0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_preview[['dealer_up', 'hand_value']])\n",
    "\n",
    "# La salida ya es binaria, asi que no hace falta normalizarla\n",
    "\n",
    "#Inputs normalizadas\n",
    "df_inputs = pd.DataFrame(X, columns=['dealer_up_normalizado', 'hand_value_normalizado'])\n",
    "\n",
    "#Concateno con la action\n",
    "df_normalizado =  pd.concat([df_inputs, df_preview['action'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "df_normalizado.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1d63c",
   "metadata": {},
   "source": [
    "## PARTE 2 - DESARROLLO DE LA RED NEURONAL\n",
    "\n",
    "Ya con los datos preparados vamos a comenzar haciendo un test de presicion con la red sin entrenar aplicando Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7af0c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.4378405778735268\n"
     ]
    }
   ],
   "source": [
    "# Con 100.000 datos, usamos el 20% como conjunto de prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_inputs, outputs, test_size=0.2)\n",
    "\n",
    "# Guardo el numero de registros de entrenamiento\n",
    "n = X_train.shape[0]\n",
    "\n",
    "# Construimos una red neuronal simple con pesos y sesgos\n",
    "w_hidden = np.random.rand(3, 2)  # Tenemos 2 entradas, son las dimensiones de la matriz\n",
    "w_output = np.random.rand(1, 3)\n",
    "\n",
    "b_hidden = np.random.rand(3, 1)\n",
    "b_output = np.random.rand(1, 1)\n",
    "\n",
    "# Defino las funciones activación\n",
    "relu = lambda x: np.maximum(x, 0)  # Convierte todos los valores negativos en 0\n",
    "logistic = lambda x: 1 / (1 + np.exp(-x))  # Es la función sigmoide, convierte todos los valores de salida a un número entre 1 y 0\n",
    "\n",
    "# Defino la función forward_prop, que es la fórmula tradicional de Descenso de Gradiente Estocástico\n",
    "def forward_prop(X):\n",
    "    Z1 = w_hidden @ X + b_hidden  # Aplico la fórmula con la entrada\n",
    "    A1 = relu(Z1)                 # Primera función activación\n",
    "    Z2 = w_output @ A1 + b_output # Hago la fórmula con la salida anterior activada\n",
    "    A2 = logistic(Z2)             # Salida activada\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Calculo de precisión\n",
    "test_predictions = forward_prop(X_test.T)[3]  # Me interesa solo la capa de salida (A2)\n",
    "\n",
    "test_comparisons = np.equal(test_predictions >= 0.5, Y_test.values.reshape(1, -1)).astype(int) # Devuelve true si la prediccion fue mayor a 0.5, y asegura q los valores de Y_test tengan la misma forma\n",
    "accuracy = np.mean(test_comparisons)\n",
    "print(\"ACCURACY: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c70e96",
   "metadata": {},
   "source": [
    "Como vemos en el resultado de la acurracy, nuestra red no entrenada acierta menos de la mitad de las veces, que no es ideal, por lo que ahora vamos a hacer **Backpropagation**, aplicando **descenso de gradiente estocastico** para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c907393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.9036877455328856\n"
     ]
    }
   ],
   "source": [
    "# En primer lugar vamos a declarar una taza de aprendizaje para nuestra red\n",
    "L = 0.01\n",
    "\n",
    "# Luego, derivamos las funciones de activacion, que nos serviran para calcular derivadas parciales a la hora de definir BackPropagation\n",
    "d_relu = lambda x: x > 0\n",
    "d_logistic = lambda x: np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "\n",
    "\n",
    "# Definimos Backpropagation\n",
    "def backward_prop(Z1, A1, Z2, A2, X, Y):\n",
    "    dC_dA2 = 2 * A2 - 2 * Y\n",
    "    dA2_dZ2 = d_logistic(Z2)\n",
    "    dZ2_dA1 = w_output\n",
    "    dZ2_dW2 = A1\n",
    "    dZ2_dB2 = 1\n",
    "    dA1_dZ1 = d_relu(Z1)\n",
    "    dZ1_dW1 = X\n",
    "    dZ1_dB1 = 1\n",
    "\n",
    "    dC_dW2 = dC_dA2 @ dA2_dZ2 @ dZ2_dW2.T\n",
    "\n",
    "    dC_dB2 = dC_dA2 @ dA2_dZ2 * dZ2_dB2\n",
    "\n",
    "    dC_dA1 = dC_dA2 @ dA2_dZ2 @ dZ2_dA1\n",
    "\n",
    "    dC_dW1 = dC_dA1 @ dA1_dZ1 @ dZ1_dW1.T\n",
    "\n",
    "    dC_dB1 = dC_dA1 @ dA1_dZ1 * dZ1_dB1\n",
    "\n",
    "    return dC_dW1, dC_dB1, dC_dW2, dC_dB2\n",
    "\n",
    "# Ejecutamos el Descenso de gradiente\n",
    "for i in range(100_000):\n",
    "    # Elijo aleatoriamente uno de los datos dedicados a entrenamiento (el otro 80%)\n",
    "    idx = np.random.choice(n, 1, replace=False)\n",
    "    X_sample = X_train.iloc[idx].values.T # Forma (2,1)\n",
    "    Y_sample = Y_train.iloc[idx].values.reshape(1,1) # Forma (1,1)\n",
    "\n",
    "    # Paso los datos seleccionados por la red neuronal de forma aleatoria\n",
    "    Z1, A1, Z2, A2 = forward_prop(X_sample)\n",
    "\n",
    "    # Aplico retropropagacion para distribuir errores y devolver pendientes para los pesos y los sesgos\n",
    "    dW1, dB1, dW2, dB2 = backward_prop(Z1, A1, Z2, A2, X_sample, Y_sample)\n",
    "\n",
    "    # Actualizo los pesos y los sesgos\n",
    "    w_hidden -= L * dW1\n",
    "    b_hidden -= L * dB1\n",
    "    w_output -= L * dW2\n",
    "    b_output -= L * dB2\n",
    "\n",
    "# Calculo de precision actualizado\n",
    "test_predictions = forward_prop(X_test.T)[3]\n",
    "test_comparisons = np.equal(test_predictions >= 0.5, Y_test.values.reshape(1, -1)).astype(int)\n",
    "accuracy = np.mean(test_comparisons)\n",
    "print(\"ACCURACY: \", accuracy)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
